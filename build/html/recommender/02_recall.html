<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>2. 召回 &mdash; fong alpha documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
      <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="3. 粗排" href="03_prerank.html" />
    <link rel="prev" title="1. 概述" href="01_introduction.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> fong
            <img src="../_static/logo.jpg" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                alpha
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">目录</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../link/index.html">快速访问</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpp/index.html">C/C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="../python/index.html">Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../linux/index.html">Linux/Shell</a></li>
<li class="toctree-l1"><a class="reference internal" href="../git/index.html">Git</a></li>
<li class="toctree-l1"><a class="reference internal" href="../machineLearning/index.html">机器学习</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deepLearning/index.html">深度学习</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mathematicsAlgorithm/index.html">数理与算法</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">推荐系统</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="01_introduction.html">1. 概述</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">2. 召回</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id3">2.1. 协同过滤</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#memory-based-collaborative-filtering">Memory-Based Collaborative Filtering</a></li>
<li class="toctree-l4"><a class="reference internal" href="#model-based-collaborative-filtering">Model-Based Collaborative Filtering</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id5">2.2. Swing</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id6">2.3. 向量化召回</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id7">负样本</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#loss">2.4. Loss</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id9">2.5. 离线指标</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id11">2.6. 参考资料</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="03_prerank.html">3. 粗排</a></li>
<li class="toctree-l2"><a class="reference internal" href="04_rank.html">4. 精排</a></li>
<li class="toctree-l2"><a class="reference internal" href="05_rerank.html">5. 重排</a></li>
<li class="toctree-l2"><a class="reference internal" href="06_ee.html">6. 探索和利用</a></li>
<li class="toctree-l2"><a class="reference internal" href="07_metric.html">7. 评价指标</a></li>
<li class="toctree-l2"><a class="reference internal" href="08_llm.html">8. 推荐与大语言模型</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../regularExpression/index.html">正则表达式</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cron/index.html">Cron 表达式</a></li>
<li class="toctree-l1"><a class="reference internal" href="../computerNetwork/index.html">计算机网络</a></li>
<li class="toctree-l1"><a class="reference internal" href="../softwares/index.html">实用软件</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tech/index.html">技巧</a></li>
<li class="toctree-l1"><a class="reference internal" href="../else/index.html">其他</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">fong</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="index.html">推荐系统</a> &raquo;</li>
      <li><span class="section-number">2. </span>召回</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/recommender/02_recall.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="id1">
<h1><span class="section-number">2. </span>召回<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h1>
<p>召回针对的是索引库中的全部 Item，主要作用是实行炮火覆盖、全面打击，将 User 的兴趣一网打尽，
因此很多时候召回往往不是一路召回而是多路召回，每一路召回都从不同的用户兴趣出发点去捞取一定量的 Item，
然后再将每一路召回的 Item 融合去重再送入粗排。</p>
<ul class="simple">
<li><dl class="simple">
<dt>统计</dt><dd><p>热度，LBS</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>协同过滤</dt><dd><p>UserCF，ItemCF</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>U2T2I</dt><dd><p>基于 User Tag 召回</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>I2I</dt><dd><p><a class="reference external" href="https://arxiv.org/pdf/2010.05525.pdf">Swing</a> ，Embedding（Word2Vec、FastText），Graph Embedding（Node2Vec、DeepWalk、EGES）</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>U2I</dt><dd><p><a class="reference external" href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/cikm2013_DSSM_fullversion.pdf">DSSM 双塔</a> ， <a class="reference external" href="https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/45530.pdf">Youtube DNN</a> ，Sentence Bert</p>
</dd>
</dl>
</li>
</ul>
<p>召回处于整体推荐链条的前端，其结果经过粗排、精排两次筛选，作用于最终业务指标时，影响力就大大减弱了。
受限于巨大的候选集和实时性要求，召回模型的复杂度受限，不能上太复杂的模型。</p>
<section id="id3">
<h2><span class="section-number">2.1. </span><a class="reference external" href="https://zh.wikipedia.org/wiki/%E5%8D%94%E5%90%8C%E9%81%8E%E6%BF%BE">协同过滤</a><a class="headerlink" href="#id3" title="Permalink to this headline"></a></h2>
<p>协同过滤（Collaborative Filtering）是一种在推荐系统中广泛使用的技术。
该技术通过分析 User 或者 Item 之间的相似性（“协同”），来预测用户可能感兴趣的内容并将其推荐给用户。这里的相似性可以是人口特征（性别、年龄、居住地等）的相似性，也可以是历史浏览内容的相似性（比如都关注过和中餐相关的内容）等。比如，用户 A 和 B 都是居住在北京的年龄在 20-30 岁的女性，并且都关注过化妆品和衣物相关的内容，这种情况下，协同过滤可能会认为 A 和 B 相似程度很高，于是可能会把 A 关注但 B 没有关注的内容推荐给 B，反之亦然。</p>
<section id="memory-based-collaborative-filtering">
<h3>Memory-Based Collaborative Filtering<a class="headerlink" href="#memory-based-collaborative-filtering" title="Permalink to this headline"></a></h3>
<p>其实就是基于最近邻的协同过滤，可分为两类：</p>
<ul>
<li><p>基于用户（User-Based）的协同过滤</p>
<ol class="arabic simple">
<li><p>收集用户信息。</p></li>
<li><p>最近邻搜索(Nearest Neighbor Search, NNS)，计算用户之间的相似度。</p></li>
<li><p>产生推荐结果。例如：透过对 A 用户的最近邻用户进行统计，选择出现频率高且在 A 用户的评分项目中不存在的推荐给A。</p></li>
</ol>
</li>
<li><p>基于项目（Item-Based）的协同过滤</p>
<p>基本假设：能够引起用户兴趣的项目，必定与其之前评分高的项目相似。</p>
<ol class="arabic simple">
<li><p>收集用户信息。</p></li>
<li><p>针对项目的最近邻搜索，计算项目之间的相似度。</p></li>
<li><p>产生推荐结果。由于未考虑用户间的差别，所以精度比较差。但是却不需要用户的历史数据，或是进行用户识别。对于项目来讲，它们之间的相似性要稳定很多，因此可以离线完成工作量最大的相似性计算步骤，从而降低了在线计算量，提高推荐效率。</p></li>
</ol>
</li>
</ul>
</section>
<section id="model-based-collaborative-filtering">
<h3>Model-Based Collaborative Filtering<a class="headerlink" href="#model-based-collaborative-filtering" title="Permalink to this headline"></a></h3>
<p>Memory-Based Collaborative Filtering 缺点是数据稀疏，难以处理大数据量，会影响即时结果。
以模型为基础的协同过滤是先用历史数据得到一个模型（关联算法、聚类、分类、矩阵分解等），再用此模型进行预测。</p>
<p>矩阵分解方法基于 User-Item 关系矩阵 <span class="math notranslate nohighlight">\(R \in \mathbb{R}^{m \times n}\)</span> 的 <strong>低秩性</strong> 假设（某些行/列存在相关性），对其进行分解，比如：</p>
<div class="math notranslate nohighlight">
\[R = PQ^{\top}\]</div>
<p>其中 <span class="math notranslate nohighlight">\(P \in \mathbb{R}^{m \times d},\ Q \in \mathbb{R}^{n \times d},\ d \ll m,n\)</span> 。优化目标是观测到的样本的 MSE Loss + L2 正则。
这样一来，衡量一对 User 和 Item 之间的相关性只要计算两个向量 <span class="math notranslate nohighlight">\(\boldsymbol{p}\)</span> 和 <span class="math notranslate nohighlight">\(\boldsymbol{q}\)</span> 之间的相似度。</p>
</section>
</section>
<section id="id5">
<h2><span class="section-number">2.2. </span><a class="reference external" href="https://arxiv.org/pdf/2010.05525.pdf">Swing</a><a class="headerlink" href="#id5" title="Permalink to this headline"></a></h2>
<p>出发点：如果大量用户同时喜欢两个物品，且这些用户之间的相关性低，那么这两个物品一定是强关联。</p>
<div class="math notranslate nohighlight">
\[s(i, j)=\sum_{u \in U_{i} \cap U_{j}} \sum_{v \in U_{i} \cap U_{j}} \frac{1}{\alpha+\left|I_{u} \cap I_{v}\right|}\]</div>
<p><span class="math notranslate nohighlight">\(U_{i}\)</span> 是喜欢物品 <span class="math notranslate nohighlight">\(i\)</span> 的用户集合；<span class="math notranslate nohighlight">\(I_{u}\)</span> 是用户 <span class="math notranslate nohighlight">\(u\)</span> 喜欢的物品集合。</p>
</section>
<section id="id6">
<h2><span class="section-number">2.3. </span>向量化召回<a class="headerlink" href="#id6" title="Permalink to this headline"></a></h2>
<a class="reference internal image-reference" href="../_images/02_twoTower.png"><img alt="../_images/02_twoTower.png" class="align-center" src="../_images/02_twoTower.png" style="width: 400px;" /></a>
<p>双塔是召回+粗排的绝对主力模型。</p>
<p><strong>训练</strong>：</p>
<ul class="simple">
<li><p>User 侧特征输入一个 DNN，得到一个 User Embedding。</p></li>
<li><p>Item 侧特征输入一个 DNN，得到一个 Item Embedding。</p></li>
<li><p>两个 Embedding 做内积运算得到 Logit，进入损失函数。</p></li>
</ul>
<p><strong>离线向量化</strong>：</p>
<ul class="simple">
<li><p>所有 Item Embedding 离线推断好。</p></li>
<li><p>构建好 ANN 向量索引（比如 <a class="reference external" href="https://github.com/facebookresearch/faiss">FAISS</a> ）。</p></li>
</ul>
<p><strong>线上部署</strong>：</p>
<ul class="simple">
<li><p>实时 User 特征输入 User Tower 得到 User Embedding。</p></li>
<li><p>用 User Embedding 在 ANN 索引中查找最近邻，得到召回结果。</p></li>
</ul>
<p>User 侧信息与 Item 侧信息只有唯一一次交叉机会，就是在双塔生成各自的 Embedding 之后的那次点积，
但是这时参与交叉的 User/Item Embedding 已经是高度浓缩的了，一些细节信息已经损失，永远失去了与对侧信息交叉的机会。</p>
<section id="id7">
<h3>负样本<a class="headerlink" href="#id7" title="Permalink to this headline"></a></h3>
<p>如果说排序是特征的艺术，那么召回就是样本的艺术，特别是负样本的艺术。
<strong>要破除“召回照搬排序”的迷信，不能（只）拿“曝光未点击”做负样本</strong>。</p>
<p>离线训练数据的分布，应该与线上实际应用的数据保持一致。从线上日志获得的训练样本，已经是上一版本的召回、粗排、精排替用户筛选过的，即已经是对用户“比较靠谱”的样本了。拿这样的样本训练出来的模型做召回，一叶障目，只见树木，不见森林。</p>
<p>基本思想：拿点击样本做正样本，拿随机采样做负样本。</p>
<ul class="simple">
<li><dl class="simple">
<dt>全局随机负采样</dt><dd><p>随机从全场景曝光过 Item 采样，使用 Listwise 存储负样本，能够最大程度保证数据分布一致，但随机采样的负样本有可能跟正样本差异大。</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>In Batch 负采样</dt><dd><p>Batch 内负采样是有损的，但实验对比在可接受范围内，而且负样本都是其他正样本，因此具有一定热度打压的作用。</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Popularity 负采样</dt><dd><p>基于随机负采样，加入热度 Item 作为负样本。因为热门 Item 没有作为正样本，那么极有可能该 Item 是不相关或者用户不感兴趣。</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Hard 负采样</dt><dd><p>模型在训练/Serving时，总有部分 Item 逃过模型的法眼，透传到粗排甚至精排当中。因此可以通过线上日志中找出有召回但粗排过滤的，有召回但没有曝光；又或者在训练过程当中，从 Item 库中检索相似度高于某一个阈值的 Item 并随机选取。此举可以提高模型的精度，过滤无关的 Item。</p>
</dd>
</dl>
</li>
</ul>
<p>当热门 Item 做正样本时，要降采样，减少对正样本集的绑架，避免所有人的召回结果都集中于少数热门 Item。</p>
<p>当热门 Item 做负样本时，要适当过采样，抵销热门 Item 对正样本集的绑架；同时，也要保证冷门 Item 在负样本集中有出现的机会。</p>
</section>
</section>
<section id="loss">
<h2><span class="section-number">2.4. </span>Loss<a class="headerlink" href="#loss" title="Permalink to this headline"></a></h2>
<p><a class="reference external" href="https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/45530.pdf">Youtube DNN</a> 模型选择了 Sampled Softmax Loss 作为损失函数。
对于二分类而言，BCE Loss 只是比较正负样本的差距，而且每次 Loss 的计算中，都是判断一个样本是正还是负，并没有纵向的对比。
对于 Softmax Loss 而言，其是一次性进行多个 Item 之间的比较，而且在每一次的 Loss 计算中，都会将正样本和多个负样本进行比较，并且告诉模型正样本是和这一批负样本很不同的。Softmax Loss 训练出来的 Embedding 的区分性更好。
直观上，这种 Loss 的优化目标和向量化召回是更一致的。</p>
<p><a class="reference external" href="https://arxiv.org/pdf/2006.11632.pdf">EBF</a> 采用的是 Triplet Loss。</p>
</section>
<section id="id9">
<h2><span class="section-number">2.5. </span>离线指标<a class="headerlink" href="#id9" title="Permalink to this headline"></a></h2>
<ul>
<li><dl class="simple">
<dt>Recall，Precision</dt><dd><p><span class="math notranslate nohighlight">\(R(u)\)</span> 表示召回 Item 的集合，<span class="math notranslate nohighlight">\(A(u)\)</span> 表示用户感兴趣的 Item 的集合（比如点击过的 Item）。</p>
</dd>
</dl>
<div class="math notranslate nohighlight">
\[\begin{split}\mathrm{recall} &amp; = \frac{\sum_{u} | R(u) \cap A(u) |}{\sum_{u} | A(u) |} = \frac{\#hits}{\sum_{u} | A(u) |} \\
\mathrm{precision} &amp; = \frac{\sum_{u} | R(u) \cap A(u) |}{\sum_{u} | R(u) |}\end{split}\]</div>
</li>
<li><dl>
<dt><a class="reference external" href="https://www.researchgate.net/publication/221141030_Performance_of_recommender_algorithms_on_top-N_recommendation_tasks">NS-Recall，NS-Precision</a></dt><dd><p>负采样的召回和准确率，主要针对 Top-N 这类召回设计，用于衡量算法相对于随机能否发现用户兴趣。
对于每一个正例 Item，都随机采样一些负样本，打分、排序，然后在这个只有一个正样本的排序列表中计算 Recall 和 Precision（只有 <span class="math notranslate nohighlight">\(0\)</span> 和 <span class="math notranslate nohighlight">\(\frac{1}{N}\)</span> 两种可能）。</p>
<p><span class="math notranslate nohighlight">\(T\)</span> 是所有正例 Item 的个数。</p>
</dd>
</dl>
<div class="math notranslate nohighlight">
\[\begin{split}\mathrm{recall}&#64;N &amp; = \frac{\#hits}{| T |} \\
\mathrm{precision}&#64;N &amp; = \frac{\#hits}{N \cdot | T |} = \frac{\mathrm{recall}&#64;N}{N}\end{split}\]</div>
</li>
<li><dl class="simple">
<dt><a class="reference external" href="https://www.researchgate.net/publication/262214507_Sparse_linear_methods_with_side_information_for_Top-N_recommendations">Hit Rate，Average Reciprocal Hit-Rank</a></dt><dd><p>ARHR 度量了一个 Item 被推荐的强烈程度。</p>
</dd>
</dl>
<div class="math notranslate nohighlight">
\[\begin{split}\mathrm{hr} &amp; = \frac{\#hits}{\#users} \\
\mathrm{arhr} &amp; = \frac{1}{\#users} \sum_i^{\#hits} \frac{1}{rank_i}\end{split}\]</div>
</li>
</ul>
<p>还需要考虑召回的丰富度（比如类目）、和其他路的重合度等。</p>
<p>此外，推荐系统中长尾效应十分明显，上述指标易受到头部数据的干扰，且大部分召回对尾部的学习不如头部数据好，因此可以增加单独的 <a class="reference external" href="https://www.researchgate.net/publication/262214507_Sparse_linear_methods_with_side_information_for_Top-N_recommendations">长尾指标</a> 。</p>
</section>
<section id="id11">
<h2><span class="section-number">2.6. </span>参考资料<a class="headerlink" href="#id11" title="Permalink to this headline"></a></h2>
<ol class="arabic simple">
<li><p>推荐系统[四]：精排-详解排序算法LTR (Learning to Rank)</p></li>
</ol>
<blockquote>
<div><p><a class="reference external" href="https://www.cnblogs.com/ting1/p/17166976.html">https://www.cnblogs.com/ting1/p/17166976.html</a></p>
</div></blockquote>
<ol class="arabic simple" start="2">
<li><p>负样本为王：评Facebook的向量化召回算法</p></li>
</ol>
<blockquote>
<div><p><a class="reference external" href="https://zhuanlan.zhihu.com/p/165064102">https://zhuanlan.zhihu.com/p/165064102</a></p>
</div></blockquote>
<ol class="arabic simple" start="3">
<li><p>Embedding-based Retrieval in Facebook Search</p></li>
</ol>
<blockquote>
<div><p><a class="reference external" href="https://arxiv.org/pdf/2006.11632.pdf">https://arxiv.org/pdf/2006.11632.pdf</a></p>
</div></blockquote>
<ol class="arabic simple" start="4">
<li><p>久别重逢话双塔</p></li>
</ol>
<blockquote>
<div><p><a class="reference external" href="https://zhuanlan.zhihu.com/p/428396126">https://zhuanlan.zhihu.com/p/428396126</a></p>
</div></blockquote>
<ol class="arabic simple" start="5">
<li><p>推荐算法召回-粗排-精排链路总结</p></li>
</ol>
<blockquote>
<div><p><a class="reference external" href="https://zhuanlan.zhihu.com/p/463021052">https://zhuanlan.zhihu.com/p/463021052</a></p>
</div></blockquote>
<ol class="arabic simple" start="6">
<li><p>一文说尽推荐系统的召回模型</p></li>
</ol>
<blockquote>
<div><p><a class="reference external" href="https://zhuanlan.zhihu.com/p/585495313">https://zhuanlan.zhihu.com/p/585495313</a></p>
</div></blockquote>
<ol class="arabic simple" start="7">
<li><p>推荐系统[八]算法实践总结V1：淘宝逛逛and阿里飞猪个性化推荐：召回算法实践总结【冷启动召回、复购召回、用户行为召回等算法实战】</p></li>
</ol>
<blockquote>
<div><p><a class="reference external" href="https://zhuanlan.zhihu.com/p/609366598?utm_id=0">https://zhuanlan.zhihu.com/p/609366598?utm_id=0</a></p>
</div></blockquote>
<ol class="arabic simple" start="8">
<li><p>Trust your neighbors: A comprehensive survey of neighborhood-based methods for recommender systems</p></li>
</ol>
<blockquote>
<div><p><a class="reference external" href="https://arxiv.org/pdf/2109.04584.pdf">https://arxiv.org/pdf/2109.04584.pdf</a></p>
</div></blockquote>
<ol class="arabic simple" start="9">
<li><p>召回常用评估指标</p></li>
</ol>
<blockquote>
<div><p><a class="reference external" href="https://juejin.cn/post/6844904065638350861">https://juejin.cn/post/6844904065638350861</a></p>
</div></blockquote>
<ol class="arabic simple" start="10">
<li><p>推荐系统之矩阵分解家族</p></li>
</ol>
<blockquote>
<div><p><a class="reference external" href="https://zhuanlan.zhihu.com/p/35262187">https://zhuanlan.zhihu.com/p/35262187</a></p>
</div></blockquote>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="01_introduction.html" class="btn btn-neutral float-left" title="1. 概述" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="03_prerank.html" class="btn btn-neutral float-right" title="3. 粗排" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2018-2024, fong.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
<script type="text/javascript">
    $(document).ready(function() {
     $(".toggle > *").hide();
     $(".toggle .header").show();
     $(".toggle .header").click(function() {
      $(this).parent().children().not(".header").toggle(400);
      $(this).parent().children(".header").toggleClass("open");
     })
    });
</script>


</body>
</html>